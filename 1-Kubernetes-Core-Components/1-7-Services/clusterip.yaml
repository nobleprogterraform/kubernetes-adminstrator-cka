apiVersion: v1
kind: Service
metadata:
 name: backend
spec:
 type: ClusterIP
 ports:
 - targetPort: 80
   port: 80
 selector:
   app: myapp
   type: backend


Service: ClusterIP
	- You may have a number of pods running a front end web servers, another set of pods running a backend server,
		a set of pods running a key value store like Redis and another set of pods may be running a persistent database like MySQL.
		The web front end server needs to communicate to the backend servers, and the backend servers need to communicate
		to the database as well as the Redis services, et cetera
	- So what is the right way to establish connectivity between these services or tiers of my application?
		The pods all have an IP address assigned to them, but these IPs, as we know, are not static.
		These pods can go down anytime and new pods are created all the time and so you cannot rely on these IP addresses
		for internal communication between the application
	- A Kubernetes service can help us group the pods together and provide a single interface to access the pods
		in a group
	- This enables us to easily and effectively deploy a microservices based application on Kubernetes cluster.
		Each layer can now scale or move as required without impacting communication
		between the various services. Each service gets an IP and name assigned to it inside the cluster, and that 
		is the name that should be used by other pods to access the service.
		This type of service is known as ClusterIP
	- apiVersion:v1, kind:Service, spec: type: ClusterIP(default) ports: -targetPort:80 port:80


 Service: LoadBalancer
	- To load balance requests on the all nodes in the cluster where pods are running 
	- Only usable on cloud platforms with support of native load balancer (eg AWS, GCP, Azure etc)
	- Service definition is similar to NodePort except type: LoadBalancer

 Imparative commands for certification help
	- If you simply want to test your command , use the --dry-run=client option. This will not create the resource, instead, 
		tell you whether the resource can be created and if your command is right
	- -o yaml: This will output the resource definition in YAML format on screen.
	- Create an NGINX Pod: kubectl run nginx --image=nginx
	- Generate POD Manifest YAML file: kubectl run nginx --image=nginx --dry-run=client -o yaml
	- Create a deployment: kubectl create deployment --image=nginx nginx
	- Generate Deployment YAML file: kubctl create deployment --image=nginx nginx --dry-run=client -o yaml
	- Generate Deployment with 4 Replicas: kubectl create deployment --image=nginx nginx --dry-run=client --replicas=4
	- You can also scale a deployment using the kubectl scale command: kubectl scale deployment nginx --relicas=4
	- Create a Service named redis-service of type ClusterIP to expose pod redis on port 6379:
		kubectl expose pod redis --port=6739 --name redis-server --dry-run=client -o yaml
		(This will automatically use the pod's labels as selectors)
		or kubectl create service clusterip redis --tcp=6379:6379 --dry-run=client -o yaml 
		(This will not use the pods labels as selectors, instead it will assume selectors as app=redis. 
		You cannot pass in selectors as an option. So it does not work very well if your pod has a different label set. 
		So generate the file and modify the selectors before creating the service)
	- Create a pod called httpd using the image httpd:alpine in the default namespace. 
		Next, create a service of type ClusterIP by the same name (httpd). The target port for the service should be 80
		kubectl run httpd --image=httpd:alpine --port=80 --expose
		
kubectl apply command:
	- kubectl apply command can be used to manage objects in a declarative way.
	- apart from our local configuration file wiht object definitions, k8s manages a live configuration and a configuration
		json file called last applied confi
